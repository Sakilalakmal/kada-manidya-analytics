# ğŸ“Š Kada Mandiya Analytics

<div align="center">

**Enterprise-grade Analytics Platform for Kada Mandiya E-commerce**

[![Python](https://img.shields.io/badge/Python-3.11+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![SQL Server](https://img.shields.io/badge/SQL%20Server-CC2927?style=for-the-badge&logo=microsoft-sql-server&logoColor=white)](https://www.microsoft.com/sql-server)
[![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)
[![RabbitMQ](https://img.shields.io/badge/RabbitMQ-FF6600?style=for-the-badge&logo=rabbitmq&logoColor=white)](https://www.rabbitmq.com/)

</div>

---

## ğŸ¯ Overview

**Kada Mandiya Analytics** is a comprehensive, production-ready analytics and business intelligence platform designed specifically for the [Kada Mandiya](https://github.com/Sakilalakmal/kada_mandiya_microservice) e-commerce ecosystem.  Built with modern data engineering principles, this platform provides real-time event tracking, advanced ETL pipelines, and actionable business insights through a multi-layered data warehouse architecture.

### ğŸŒŸ Key Capabilities

- **ğŸ“ˆ Real-time Event Processing**: Event-driven architecture consuming domain events from RabbitMQ
- **ğŸ—ï¸ Medallion Architecture**: Bronze â†’ Silver â†’ Gold data transformation pipeline
- **ğŸ”„ Automated ETL Jobs**: Scheduled data processing with distributed locking mechanisms
- **ğŸ“Š Business Intelligence**: Pre-built analytics models for conversion funnels, revenue analysis, and customer insights
- **ğŸš€ High Performance**: Optimized SQL Server warehousing with connection pooling and retry logic
- **ğŸ” Secure API**: Protected REST endpoints for analytics data access
- **ğŸ­ Multiple Event Types**: Tracks user behavior, business events, API performance, and database queries

---

## ğŸ›ï¸ Architecture

### Data Flow Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Kada Mandiya Microservices                       â”‚
â”‚         (Order, Payment, Review, Product, User Services)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   RabbitMQ     â”‚
                    â”‚  Event Broker  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Analytics Consumer     â”‚
              â”‚  (Event Ingestion)      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚    BRONZE Layer          â”‚
              â”‚  (Raw Event Storage)     â”‚
              â”‚  - page_view_events      â”‚
              â”‚  - click_events          â”‚
              â”‚  - business_events       â”‚
              â”‚  - api_request_logs      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚    SILVER Layer          â”‚
              â”‚ (Cleaned & Enriched)     â”‚
              â”‚  - orders                â”‚
              â”‚  - product_interactions  â”‚
              â”‚  - user_sessions         â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚    GOLD Layer            â”‚
              â”‚  (Business Metrics)      â”‚
              â”‚  - conversion_funnel     â”‚
              â”‚  - revenue_metrics       â”‚
              â”‚  - customer_analytics    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Analytics API          â”‚
              â”‚  (FastAPI REST)          â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Warehouse Layers

| Layer | Purpose | Examples |
|-------|---------|----------|
| **ğŸ¥‰ Bronze** | Raw, immutable event data | Page views, clicks, business events, API logs |
| **ğŸ¥ˆ Silver** | Cleaned, validated, deduplicated | Orders, user sessions, product interactions |
| **ğŸ¥‡ Gold** | Aggregated business metrics | Conversion funnels, revenue analytics, cohort analysis |
| **âš™ï¸ Ops** | Operational metadata | ETL run logs, dead letter queue, locks |

---

## ğŸš€ Getting Started

### Prerequisites

- **Python**:  3.11 or higher
- **SQL Server**: 2019+ or Azure SQL Database
- **RabbitMQ**: 3.9+ (for event consumption)
- **ODBC Driver**:  ODBC Driver 18 for SQL Server

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/Sakilalakmal/kada-manidya-analytics.git
   cd kada-manidya-analytics
   ```

2. **Set up virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables**
   ```bash
   cp .env.example .env
   # Edit .env with your configuration
   ```

### Configuration

Create a `.env` file with the following settings:

```env
# Database Configuration
DB_HOST=localhost
DB_PORT=1433
DB_USER=analytics_user
DB_PASSWORD=your_secure_password
DB_NAME=kada_analytics
DB_DRIVER=ODBC Driver 18 for SQL Server
DB_TRUST_CERT=yes

# RabbitMQ Configuration
RABBITMQ_URL=amqp://guest:guest@localhost:5672/
RABBITMQ_EXCHANGE=domain. events
RABBITMQ_EXCHANGE_TYPE=topic
RABBITMQ_QUEUE=analytics.business.events
RABBITMQ_ROUTING_KEYS=order.*,payment.*,review.*
RABBITMQ_PREFETCH=50
ANALYTICS_CONSUMER_ENABLED=true

# ETL Job Configuration
ETL_INTERVAL_SECONDS=300
ETL_ENABLE_SILVER=true
ETL_ENABLE_GOLD=true
ETL_MAX_INSTANCES=1
ETL_COALESCE=true
ETL_MISFIRE_GRACE_SECONDS=30

# API Security
ANALYTICS_API_KEY=your_api_key_here
```

### Database Setup

1. **Create the data warehouse**
   ```bash
   python -m src.etl.01_create_warehouse
   ```

2. **Run initial ETL pipeline**
   ```bash
   python -m src.jobs.runner --once
   ```

---

## ğŸ“¦ Core Components

### 1. Event Models (`src/models/`)

Comprehensive event schema definitions using Pydantic:

- **`BaseEvent`**: Foundation for all analytics events
- **`PageViewEvent`**: User page navigation tracking
- **`ClickEvent`**: Click-stream analytics
- **`SearchEvent`**: Search behavior analysis
- **`CartActionEvent`**: Shopping cart interactions
- **`BusinessEvent`**: Domain events (orders, payments, reviews)
- **`PerformanceEvent`**: Application performance metrics
- **`ApiRequestLogEvent`**: API call tracking
- **`DbQueryPerfEvent`**: Database query performance

### 2. ETL Pipeline (`src/etl/`)

Multi-stage data transformation pipeline:

- **`01_create_warehouse. py`**: Schema initialization
- **`02b_seed_business_events.py`**: Bronze layer event ingestion
- **`03_build_silver. py`**: Data cleaning and enrichment
- **`04_build_gold.py`**: Business metrics aggregation

### 3. Job Orchestration (`src/jobs/`)

- **`runner.py`**: One-time ETL execution
- **`scheduler.py`**: Scheduled background jobs using APScheduler
- **`pipeline.py`**: Orchestrates multi-stage ETL flows
- **`locking.py`**: Distributed lock mechanism to prevent concurrent runs

### 4. Database Layer (`src/db/`)

- **`engine.py`**: SQLAlchemy connection management with retry logic
- **`writers.py`**: Bulk event insertion with duplicate handling

### 5. API (`src/api/`)

- **`security.py`**: API key authentication
- REST endpoints for analytics data retrieval

---

## ğŸ® Usage

### Running ETL Pipeline

**One-time execution:**
```bash
python -m src.jobs.runner --once
```

**Skip seed step (development):**
```bash
python -m src.jobs.runner --once --no-seed
```

**Scheduled execution:**
```bash
python -m src.jobs.scheduler
```

### Event Consumption

Start the RabbitMQ consumer to ingest events: 
```bash
python -m src.consumer.rabbitmq_consumer
```

### Analytics API

Launch the FastAPI server:
```bash
uvicorn src.api.main:app --host 0.0.0.0 --port 8000
```

Access API documentation: 
- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

---

## ğŸ“Š Analytics Capabilities

### Business Metrics

- **Conversion Funnel Analysis**: Track user journey from visit â†’ product view â†’ add to cart â†’ purchase
- **Revenue Analytics**: Daily/weekly/monthly revenue trends and projections
- **Customer Segmentation**: RFM (Recency, Frequency, Monetary) analysis
- **Product Performance**: Best sellers, inventory turnover, category analytics
- **User Behavior**: Session analysis, page flow, bounce rates

### Event Tracking

```python
from src.models.events import PageViewEvent
from src.db.writers import insert_page_view

event = PageViewEvent(
    event_timestamp=datetime.utcnow(),
    session_id="sess_123",
    user_id="user_456",
    source="web",
    page_url="/products/smartphone-x",
    utm_source="google",
    utm_campaign="summer_sale"
)
```

---

## ğŸ”’ Security Features

- **API Key Authentication**: Secured REST endpoints
- **SQL Injection Prevention**: Parameterized queries via SQLAlchemy
- **Connection Encryption**: TLS/SSL for database connections
- **Environment Isolation**: Sensitive credentials via environment variables

---

## ğŸ§ª Development

### Project Structure

```
kada-mandiya-analytics/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/              # FastAPI REST endpoints
â”‚   â”œâ”€â”€ consumer/         # RabbitMQ event consumers
â”‚   â”œâ”€â”€ db/               # Database engine and writers
â”‚   â”œâ”€â”€ etl/              # ETL pipeline scripts
â”‚   â”œâ”€â”€ jobs/             # Job orchestration
â”‚   â”œâ”€â”€ models/           # Pydantic event models
â”‚   â”œâ”€â”€ ops/              # Operational utilities
â”‚   â””â”€â”€ utils/            # Helper functions
â”œâ”€â”€ tests/                # Test suites
â”œâ”€â”€ . env.example          # Environment template
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md
```

### Code Quality

- **Type Hints**: Full type annotations with `mypy` support
- **Pydantic Validation**: Automatic data validation
- **Structured Logging**: JSON-formatted logs with Loguru
- **Error Handling**: Comprehensive exception management with retry logic

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these guidelines:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-analytics`)
3. Commit your changes (`git commit -m 'Add customer cohort analysis'`)
4. Push to the branch (`git push origin feature/amazing-analytics`)
5. Open a Pull Request

---

## ğŸ“ License

This project is part of the **Kada Mandiya** e-commerce platform ecosystem. 

---

## ğŸ”— Related Projects

- **[Kada Mandiya Microservices](https://github.com/Sakilalakmal/kada_mandiya_microservice)**: Core e-commerce platform

---

## ğŸ“§ Contact

**Developer**: Sakilalakmal  
**GitHub**: [@Sakilalakmal](https://github.com/Sakilalakmal)

---

<div align="center">

**Built with â¤ï¸ for Kada Mandiya E-commerce Platform**

</div>
